{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e69907b-68d3-4222-9ef2-8c2b4f5051f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5289fc19-bf7e-4034-a605-aded35a6f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23e3950-c9cd-4c1e-9a9a-859c1eb2a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Translating English to Farsi\n",
    "# translator = GoogleTranslator(source='en', target='fa')  # 'fa' is the language code for Farsi\n",
    "# translated_text = translator.translate(\"Hello, how are you?\")\n",
    "# print(f\"Translated Text: {translated_text}\")\n",
    "\n",
    "# # Translating Farsi to English\n",
    "# translator = GoogleTranslator(source='fa', target='en')\n",
    "# translated_text_fa_to_en = translator.translate(\"سلام، حال شما چطور است؟\")\n",
    "# print(f\"Translated Text: {translated_text_fa_to_en}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df816eb8-d7d7-4ee3-8438-b184e98baba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "def load_file(path_file):\n",
    "    with open(path_file, 'r') as lines:\n",
    "        content = lines.readlines()\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230b936f-fa0a-4242-aba2-a88a7041a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str(content):\n",
    "    translator = GoogleTranslator(source='en', target='fa')\n",
    "    len_content = len(content)\n",
    "    for index, item in enumerate(content):\n",
    "        if re.match(r'^\\d+\\n$', item):\n",
    "            for i in range(2,10):\n",
    "                if (index+i) >= len_content or re.match(r'\\n$', content[index+i]) :\n",
    "                    break     \n",
    "                result = str(translator.translate(content[index+i]))\n",
    "                content[index+i] = result + '\\n'\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef775d77-a1a4-49b5-9f51-1bb5a64997f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "def save_file(file_name_new, content):\n",
    "    with open(file_name_new, 'w') as file:\n",
    "        for line in content:\n",
    "            # Write the string followed by a newline character\n",
    "            file.write(line)\n",
    "    print(f'file {file_name_new} is translate ,ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74bb68c-e0e7-4feb-afd3-e4dfffc6e366",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m srt_files:\n\u001b[1;32m      9\u001b[0m     content \u001b[38;5;241m=\u001b[39m load_file(file_name)\n\u001b[0;32m---> 10\u001b[0m     content_fa \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     file_name_new \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.srt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fa.srt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     file_name_new \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_subtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslate_subtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mconvert_str\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m+\u001b[39mi) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_content \u001b[38;5;129;01mor\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn$\u001b[39m\u001b[38;5;124m'\u001b[39m, content[index\u001b[38;5;241m+\u001b[39mi]) :\n\u001b[1;32m      8\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m     \n\u001b[0;32m----> 9\u001b[0m             result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m             content[index\u001b[38;5;241m+\u001b[39mi] \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/deep_translator/google.py:67\u001b[0m, in \u001b[0;36mGoogleTranslator.translate\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload_key:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload_key] \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m---> 67\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequests()\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/urllib3/response.py:1063\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/urllib3/response.py:1219\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ai_code/complete_ai/env_ai/lib/python3.11/site-packages/urllib3/response.py:1138\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specify the directory path and pattern for .srt files\n",
    "directory_path = 'original_subtitle/*.srt'\n",
    "\n",
    "# Find all .srt files\n",
    "srt_files = glob.glob(directory_path)\n",
    "\n",
    "# Print the found .srt files\n",
    "for file_name in srt_files:\n",
    "    content = load_file(file_name)\n",
    "    content_fa = convert_str(content)\n",
    "    file_name_new = file_name.replace(\".srt\", \"_fa.srt\")\n",
    "    file_name_new = file_name.replace(\"original_subtitle\", \"translate_subtitle\")\n",
    "    save_file(file_name_new, content_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf27e67-ba73-45c7-8f46-7e7e336e5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"001 List And List Comprehension In Python_en.srt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c12eafb-e6a1-4cb2-8984-e01e0f51ca0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(file_name, 'r') as lines:\n",
    "#     content = lines.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2695ec-91c2-426a-a97d-15733b1acc3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2257d-6d33-4fe9-9460-585a14fabd94",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len_content = len(content)\n",
    "for index, item in enumerate(content):\n",
    "    if re.match(r'^\\d+\\n$', item):\n",
    "        for i in range(2,10):\n",
    "            if (index+i) >= len(content) or re.match(r'\\n$', content[index+i]) :\n",
    "                break     \n",
    "            async with Translator() as translator:\n",
    "                result = await translator.translate(text=content[index+i], src='en', dest='fa')\n",
    "                content[index+i] = result.text + '\\n'\n",
    "\n",
    "                # ###\n",
    "                # pos = index+i\n",
    "                # list_worlds = split_en_from_fa(result.text)\n",
    "                # list_sentence = wolds_to_list(list_worlds)\n",
    "                # # Insert elements using a loop\n",
    "                # for s in range(len(list_sentence)):\n",
    "                #     content[pos + s] = list_sentence[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0666f000-3bc1-46cf-a83d-d5b3b4a22829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d076094-e329-42de-b5ac-b8a030734f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name_new = file_name.replace(\".srt\", \"_fa.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607c031e-cc26-4e4d-8eb6-b45e2b820abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_name_new, 'w') as file:\n",
    "#     for line in content:\n",
    "#         # Write the string followed by a newline character\n",
    "#         file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1fe9f-14e5-45bf-accd-bfea6b3f284a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a02052-d69b-4c39-8ac6-a7611cc5ad78",
   "metadata": {},
   "source": [
    "def starts_with_english_char(word):\n",
    "    # Check if the word is not empty and the first character is an ASCII English letter\n",
    "    return bool(word) and word[0].isascii() and word[0].isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b09b46-3abc-45a2-b834-9e7f6febd6b3",
   "metadata": {},
   "source": [
    "worlds = 'یادگیری و NLP با پروژه های پایانی و MLO با بیش از 13 سال تجربه در داده ها\\n'\n",
    "\n",
    "def split_en_from_fa(worlds):   \n",
    "    list_worlds =  worlds.split()\n",
    "    list_worlds_final = list_worlds.copy()\n",
    "    \n",
    "    check_en = False\n",
    "    index_final = 0\n",
    "    \n",
    "    for index, item in enumerate(list_worlds):\n",
    "        # print(f'{item} - {starts_with_english_char(item)}')\n",
    "        \n",
    "        if starts_with_english_char(item):\n",
    "            # print(f'{item} - {index}' )\n",
    "            # print(list_worlds_final)\n",
    "            list_worlds_final.insert(index+index_final, '\\n')\n",
    "            # print(list_worlds_final)\n",
    "            index_final += 1\n",
    "            check_en = True\n",
    "        else:\n",
    "            if check_en:\n",
    "                # print(f'{item} - {index}' )\n",
    "                # print(list_worlds_final)\n",
    "                list_worlds_final.insert(index+index_final, '\\n')\n",
    "                # print(list_worlds_final)\n",
    "                index_final += 1\n",
    "            check_en = False\n",
    "    result_string = ' '.join(list_worlds_final)\n",
    "    return(list_worlds_final)\n",
    "\n",
    "\n",
    "print(split_en_from_fa(worlds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d22999-3082-4a83-bbdc-4a8f62be9193",
   "metadata": {},
   "source": [
    "# Given list\n",
    "words = ['یادگیری', 'و', '\\n', 'NLP', '\\n', 'با', 'پروژه', 'های', 'پایانی', 'و', '\\n', 'MLO', '\\n', 'با', 'بیش', 'از', '13', 'سال', 'تجربه', 'در', 'داده', 'ها']\n",
    "\n",
    "def wolds_to_list(list_worlds):\n",
    "    # Initialize variables\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    # Iterate through the list\n",
    "    for word in list_worlds:\n",
    "        if word == '\\n':\n",
    "            # If we hit a newline, join the current sentence and reset it\n",
    "            if current_sentence:  # Check if there's something to add\n",
    "                sentences.append(\" \".join(current_sentence))\n",
    "                current_sentence = []  # Reset for next sentence\n",
    "        else:\n",
    "            # Add word to the current sentence\n",
    "            current_sentence.append(word)\n",
    "    \n",
    "    # If there's any remaining words after the last newline, add them as well\n",
    "    if current_sentence:\n",
    "        sentences.append(\" \".join(current_sentence))\n",
    "    \n",
    "    # The result is a list of sentences\n",
    "    # print(sentences)\n",
    "    return(sentences)\n",
    "\n",
    "wolds_to_list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb897d4-f4d5-4088-82aa-74788a9907bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
